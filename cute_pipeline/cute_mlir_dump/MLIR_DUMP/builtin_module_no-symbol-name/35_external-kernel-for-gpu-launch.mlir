// -----// IR Dump After ExternalKernelForGpuLaunchPass (external-kernel-for-gpu-launch) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {gpu.container_module} {
  llvm.func @printf(!llvm.ptr, ...) -> i32 loc(#loc)
  llvm.mlir.global internal constant @err_msg("call cuLaunchKernel/cuLaunchKernelEx failed, got error code: %d \0A\00") {addr_space = 0 : i32} loc(#loc)
  llvm.func @cuLaunchKernel(!llvm.ptr, i64, i64, i64, i64, i64, i64, i32, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc)
  llvm.func @cuFuncSetAttribute(!llvm.ptr, i32, i32) loc(#loc)
  gpu.binary @kernels  [#gpu.object<#nvvm.target<O = 3, chip = "sm_90a">, properties = {O = 3 : i32}, assembly = "//\0A// Generated by NVIDIA NVVM Compiler\0A//\0A// Compiler Build ID: CL-36006120\0A// Cuda compilation tools, release 12.9, V12.9.83\0A// Based on NVVM 20.0.0\0A//\0A\0A.version 8.8\0A.target sm_90a\0A.address_size 64\0A\0A\09// .globl\09kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0\0A\0A.visible .entry kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0(\0A\09.param .align 8 .b8 kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0_param_0[8],\0A\09.param .align 8 .b8 kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0_param_1[8],\0A\09.param .align 8 .b8 kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0_param_2[8]\0A)\0A.reqntid 256, 1, 1\0A{\0A\09.reg .pred \09%p<4>;\0A\09.reg .b16 \09%rs<4>;\0A\09.reg .b32 \09%r<15>;\0A\09.reg .b64 \09%rd<8>;\0A\0A\09ld.param.u64 \09%rd1, [kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0_param_2];\0A\09ld.param.u64 \09%rd2, [kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0_param_1];\0A\09ld.param.u64 \09%rd3, [kernel_cutlass_naive_elementwise_add_kernel_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_tensorptrf16gmemalign16o2048204820481_0_param_0];\0A\09mov.u32 \09%r1, %tid.x;\0A\09mov.u32 \09%r2, %ctaid.x;\0A\09mov.u32 \09%r3, %ntid.x;\0A\09mad.lo.s32 \09%r4, %r2, %r3, %r1;\0A\09shr.s32 \09%r5, %r4, 31;\0A\09shr.u32 \09%r6, %r5, 21;\0A\09add.s32 \09%r7, %r4, %r6;\0A\09and.b32  \09%r8, %r7, -2048;\0A\09sub.s32 \09%r9, %r4, %r8;\0A\09shr.u32 \09%r10, %r7, 11;\0A\09setp.ne.s32 \09%p1, %r4, %r8;\0A\09setp.lt.s32 \09%p2, %r4, 0;\0A\09and.pred  \09%p3, %p2, %p1;\0A\09selp.s32 \09%r11, -1, 0, %p3;\0A\09add.s32 \09%r12, %r10, %r11;\0A\09shl.b32 \09%r13, %r12, 11;\0A\09add.s32 \09%r14, %r13, %r9;\0A\09mul.wide.s32 \09%rd4, %r14, 2;\0A\09add.s64 \09%rd5, %rd3, %rd4;\0A\09ld.global.b16 \09%rs1, [%rd5];\0A\09add.s64 \09%rd6, %rd2, %rd4;\0A\09ld.global.b16 \09%rs2, [%rd6];\0A\09add.f16 \09%rs3, %rs1, %rs2;\0A\09add.s64 \09%rd7, %rd1, %rd4;\0A\09st.global.b16 \09[%rd7], %rs3;\0A\09ret;\0A\0A}\0A\00\00">] loc(#loc)
  llvm.func @cutlass_naive_elementwise_add_Tensorgmemo2048204820481_Tensorgmemo2048204820481_Tensorgmemo2048204820481(%arg0: !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)> loc(unknown), %arg1: !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)> loc(unknown), %arg2: !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)> loc(unknown), %arg3: !llvm.ptr loc(unknown)) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %1 = llvm.mlir.constant(256 : index) : i64 loc(#loc)
    %2 = llvm.mlir.constant(1 : index) : i64 loc(#loc)
    %3 = llvm.mlir.constant(16384 : index) : i64 loc(#loc)
    %4 = llvm.mlir.zero : !llvm.ptr loc(#loc)
    %5 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %6 = llvm.alloca %5 x !llvm.struct<(struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>)> : (i32) -> !llvm.ptr loc(#loc)
    %7 = llvm.mlir.constant(3 : i32) : i32 loc(#loc)
    %8 = llvm.alloca %7 x i64 : (i32) -> !llvm.ptr loc(#loc)
    %9 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.struct<(struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>)> loc(#loc)
    llvm.store %arg0, %9 : !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, !llvm.ptr loc(#loc)
    %10 = llvm.ptrtoint %9 : !llvm.ptr to i64 loc(#loc)
    %11 = llvm.getelementptr %8[0] : (!llvm.ptr) -> !llvm.ptr, i64 loc(#loc)
    llvm.store %10, %11 : i64, !llvm.ptr loc(#loc)
    %12 = llvm.getelementptr %6[0, 1] : (!llvm.ptr) -> !llvm.ptr, !llvm.struct<(struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>)> loc(#loc)
    llvm.store %arg1, %12 : !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, !llvm.ptr loc(#loc)
    %13 = llvm.ptrtoint %12 : !llvm.ptr to i64 loc(#loc)
    %14 = llvm.getelementptr %8[1] : (!llvm.ptr) -> !llvm.ptr, i64 loc(#loc)
    llvm.store %13, %14 : i64, !llvm.ptr loc(#loc)
    %15 = llvm.getelementptr %6[0, 2] : (!llvm.ptr) -> !llvm.ptr, !llvm.struct<(struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>)> loc(#loc)
    llvm.store %arg2, %15 : !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, !llvm.ptr loc(#loc)
    %16 = llvm.ptrtoint %15 : !llvm.ptr to i64 loc(#loc)
    %17 = llvm.getelementptr %8[2] : (!llvm.ptr) -> !llvm.ptr, i64 loc(#loc)
    llvm.store %16, %17 : i64, !llvm.ptr loc(#loc)
    %18 = llvm.mlir.constant(8 : i32) : i32 loc(#loc)
    llvm.call @cuFuncSetAttribute(%arg3, %18, %0) : (!llvm.ptr, i32, i32) -> () loc(#loc)
    %19 = llvm.mlir.zero : !llvm.ptr loc(#loc)
    %20 = llvm.call @cuLaunchKernel(%arg3, %3, %2, %2, %1, %2, %2, %0, %4, %8, %19) : (!llvm.ptr, i64, i64, i64, i64, i64, i64, i32, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc)
    %21 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %22 = llvm.icmp "ne" %20, %21 : i32 loc(#loc)
    llvm.cond_br %22, ^bb2, ^bb1 loc(#loc)
  ^bb1:  // 2 preds: ^bb0, ^bb2
    llvm.return loc(#loc)
  ^bb2:  // pred: ^bb0
    %23 = llvm.mlir.addressof @err_msg : !llvm.ptr loc(#loc)
    %24 = llvm.mlir.constant(0 : index) : i64 loc(#loc)
    %25 = llvm.getelementptr %23[%24, %24] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<66 x i8> loc(#loc)
    %26 = llvm.call @printf(%25, %20) vararg(!llvm.func<i32 (ptr, ...)>) : (!llvm.ptr, i32) -> i32 loc(#loc)
    llvm.br ^bb1 loc(#loc)
  } loc(#loc)
  llvm.func @_mlir_ciface_cutlass_naive_elementwise_add_Tensorgmemo2048204820481_Tensorgmemo2048204820481_Tensorgmemo2048204820481(%arg0: !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)> loc(unknown), %arg1: !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)> loc(unknown), %arg2: !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)> loc(unknown), %arg3: !llvm.ptr loc(unknown)) attributes {llvm.emit_c_interface} {
    llvm.call @cutlass_naive_elementwise_add_Tensorgmemo2048204820481_Tensorgmemo2048204820481_Tensorgmemo2048204820481(%arg0, %arg1, %arg2, %arg3) : (!llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, !llvm.struct<(ptr<1>, struct<(struct<()>, struct<()>)>)>, !llvm.ptr) -> () loc(#loc)
    llvm.return loc(#loc)
  } loc(#loc)
} loc(#loc)


